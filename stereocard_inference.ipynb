{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "stereocard_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8s2+SNivqn9xkI0c/kxeo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atomicguy/stereocards/blob/main/stereocard_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x57qVtWpX5CW"
      },
      "source": [
        "# Setup the Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAWEXYnHXpsD",
        "outputId": "2520f14b-a8fe-4011-cbe9-71744895d4eb"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwuhKsANX1E4",
        "outputId": "c55dd993-a3b9-48c1-d930-fa26ed32329d"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2782, done.\u001b[K\n",
            "remote: Counting objects: 100% (2782/2782), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2318/2318), done.\u001b[K\n",
            "remote: Total 2782 (delta 711), reused 1299 (delta 429), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2782/2782), 32.76 MiB | 28.17 MiB/s, done.\n",
            "Resolving deltas: 100% (711/711), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFoUnhskX2yC"
      },
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smu-cTOZa3dY"
      },
      "source": [
        "# Run the Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWedMqKNcI2u"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yo4UI2WbNPQ"
      },
      "source": [
        "import os\n",
        "\n",
        "#recover our saved model\n",
        "pipeline_config = '/content/gdrive/MyDrive/tf2/ssd-resnet50-augment/pipeline.config'\n",
        "#generally you want to put the last ckpt from training in here\n",
        "model_dir = '/content/gdrive/MyDrive/tf2/ssd-resnet50-augment/checkpoint'\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(\n",
        "      model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\n",
        "      model=detection_model)\n",
        "ckpt.restore(os.path.join('/content/gdrive/MyDrive/tf2/ssd-resnet50-augment/checkpoint/ckpt-0'))\n",
        "\n",
        "def get_model_detection_function(model):\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\n",
        "\n",
        "  @tf.function(experimental_relax_shapes=True)\n",
        "  def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = model.preprocess(image)\n",
        "    prediction_dict = model.predict(image, shapes)\n",
        "    detections = model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "  return detect_fn\n",
        "\n",
        "detect_fn = get_model_detection_function(detection_model)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lijFjnS2d-lV"
      },
      "source": [
        "#map labels for inference decoding\n",
        "label_map_path = '/content/gdrive/MyDrive/tf2/ssd-resnet50-augment/image-pairs_label_map.pbtxt'\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map,\n",
        "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "    use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX8q6r4LcT-8"
      },
      "source": [
        "import six\n",
        "\n",
        "label_id_offset = 1\n",
        "\n",
        "def filter_boxes(detections, max_boxes=2, min_score_thresh=0.5):\n",
        "  boxes = detections['detection_boxes'][0].numpy()\n",
        "  classes = (detections['detection_classes'][0].numpy() + label_id_offset).astype(int)\n",
        "  scores = detections['detection_scores'][0].numpy()\n",
        "\n",
        "  filtered_boxes = {}\n",
        "\n",
        "  for i in range(boxes.shape[0]):\n",
        "    prediction = {}\n",
        "    if scores is None or scores[i] > min_score_thresh:\n",
        "      box = boxes[i].tolist()\n",
        "      display_str = ''\n",
        "      if classes[i] in six.viewkeys(category_index):\n",
        "        class_name = category_index[classes[i]]['name']\n",
        "      else:\n",
        "        class_name = 'N/A'\n",
        "      score = scores[i]\n",
        "      prediction['x0'] = box[0]\n",
        "      prediction['y0'] = box[1]\n",
        "      prediction['x1'] = box[2]\n",
        "      prediction['y1'] = box[3]\n",
        "      prediction['class'] = class_name\n",
        "      prediction['score'] = np.float64(score)\n",
        "      filtered_boxes[class_name] = prediction\n",
        "  \n",
        "  return filtered_boxes\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_3A3lN7Ying"
      },
      "source": [
        "# Copy Images locally\n",
        "!unzip -o /content/gdrive/MyDrive/images/front_jpegs.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoLdsWFPcc2J",
        "outputId": "297cca17-0ef8-4948-e567-3b3173d33a7d"
      },
      "source": [
        "import glob\n",
        "import json\n",
        "\n",
        "from functools import singledispatch\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "test_image_paths = glob.glob('/content/front_jpegs/*.jpg')\n",
        "\n",
        "for image in tqdm (test_image_paths):\n",
        "    uuid = Path(image).stem\n",
        "    result_path = f'/content/gdrive/MyDrive/predictions/{uuid}.json'\n",
        "    if not os.path.exists(result_path):\n",
        "        try:\n",
        "            image_np = load_image_into_numpy_array(image)\n",
        "        except Exception as ex:\n",
        "            print(f'{image} failed with {ex}')\n",
        "        input_tensor = tf.convert_to_tensor(\n",
        "        np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "        try:\n",
        "            detections, _, _ = detect_fn(input_tensor)\n",
        "            results = filter_boxes(detections)\n",
        "            results['uuid'] = uuid\n",
        "\n",
        "            with open(result_path, 'w') as f:\n",
        "                json.dump(results, f)\n",
        "        except Exception as ex:\n",
        "            print(f'{image} caused by {ex}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 41810/41810 [01:53<00:00, 368.19it/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XyVsGLfa3gi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7jl6_g5ZGbC"
      },
      "source": [
        "!cp -r /content/front_jpegs/ /content/gdrive/MyDrive/images/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}